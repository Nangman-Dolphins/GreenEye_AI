# -*- coding: utf-8 -*-
"""LoRA_finetuning.ipynbì˜ ì‚¬ë³¸ì˜ ì‚¬ë³¸

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iZhJ1RGOxs0TRHxjhB1idnMkG9xSyYya
"""

!pip install torch torchvision tqdm peft accelerate transformers numpy imagehash

pip install scikit-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms, datasets
from peft import LoraConfig, get_peft_model, TaskType, PeftModel
import os
import random
import numpy as np
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

# lora_kfold_train.py
import os
import random
import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F # <-- FocalLossë¥¼ ìœ„í•´ ì¶”ê°€
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms, datasets
from peft import LoraConfig, get_peft_model, TaskType, PeftModel
from torchmetrics.classification import MulticlassF1Score

# ==============================================================================
# âš™ï¸ CONFIG
# ==============================================================================
class Config:
    FOLDS_DIR = "./ROSE_Dataset_KFOLDS"
    NUM_FOLDS = 6
    TEST_DIR = "./ROSE_Dataset/test"
    BASE_MODEL_PATH = "./plant-model-epoch=39-val_f1=0.922.ckpt"
    OUTPUT_BASE = "./LoRA_OUTPUT_Rose"
    SEED = 42
    NUM_EPOCHS = 20
    BATCH_SIZE = 32
    WEIGHT_DECAY = 0.05
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    WARMUP_EPOCHS = 2
    FC_LR = 5e-4
    LORA_LR = 1e-4
    LORA_R = 16
    LORA_ALPHA = 32
    LORA_DROPOUT = 0.2
    # --- âœ¨ ì¶”ê°€ëœ ì„¤ì •: Focal Loss ê°ë§ˆ ê°’ ---
    FOCAL_GAMMA = 2.0

# ==============================================================================
# ğŸ”§ UTILS
# ==============================================================================

# <-- âœ¨ 1ë‹¨ê³„: FocalLoss í´ë˜ìŠ¤ ì¶”ê°€ âœ¨ -->
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        if self.alpha is not None:
            alpha_t = self.alpha[targets]
            focal_loss = alpha_t * (1 - pt)**self.gamma * ce_loss
        else:
            focal_loss = (1 - pt)**self.gamma * ce_loss
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.benchmark = True

def print_trainable_parameters(model):
    t, a = 0, 0
    for _, p in model.named_parameters():
        a += p.numel()
        if p.requires_grad: t += p.numel()
    print(f"trainable params: {t} || all params: {a} || trainable%: {100*t/a:.2f}")

def freeze_bn_in_eval(model):
    for m in model.modules():
        if isinstance(m, nn.BatchNorm2d):
            m.eval()

def get_dataloaders_for_fold(FOLDS_DIR, fold_idx, TEST_DIR, batch_size, device_type):
    fold_base_dir = os.path.join(FOLDS_DIR, f"fold_{fold_idx}")
    train_dir = os.path.join(fold_base_dir, "train")
    val_dir   = os.path.join(fold_base_dir, "val")
    test_dir  = TEST_DIR

    tfm = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
        ]),
        'val_test': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
        ]),
    }

    image_datasets = {
        'train': datasets.ImageFolder(train_dir, tfm['train']),
        'val'  : datasets.ImageFolder(val_dir,   tfm['val_test']),
        'test' : datasets.ImageFolder(test_dir,  tfm['val_test']),
    }

    dataloaders = {
        'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True,
                            num_workers=2, pin_memory=(device_type=='cuda')),
        'val'  : DataLoader(image_datasets['val'],   batch_size=batch_size, shuffle=False,
                            num_workers=2, pin_memory=(device_type=='cuda')),
        'test' : DataLoader(image_datasets['test'],  batch_size=batch_size, shuffle=False,
                            num_workers=2, pin_memory=(device_type=='cuda')),
    }
    num_classes = len(image_datasets['train'].classes)
    class_names = image_datasets['train'].classes
    return dataloaders, image_datasets, num_classes, class_names

def build_lora_resnet50(num_classes, base_model_path, device, cfg: Config):
    model = models.resnet50(weights=None)
    in_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.4),
        nn.Linear(in_features, num_classes)
    )

    for n, p in model.named_parameters():
        p.requires_grad = n.startswith("fc.")

    try:
        checkpoint = torch.load(base_model_path, map_location="cpu", weights_only=False)
        state_dict = checkpoint.get("state_dict", checkpoint)
        cleaned_state_dict = {k.replace("resnet.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(cleaned_state_dict, strict=False)
        print("Base model weights loaded successfully.")
    except Exception as e:
        print(f"Could not load base model weights: {e} (continue).")

    conv_targets = [name for name, m in model.named_modules() if isinstance(m, nn.Conv2d)]
    lora_conf = LoraConfig(
        r=cfg.LORA_R, lora_alpha=cfg.LORA_ALPHA, lora_dropout=cfg.LORA_DROPOUT,
        target_modules=conv_targets, bias="none"
    )
    model = get_peft_model(model, lora_conf)
    print_trainable_parameters(model)
    return model.to(device)

# --- âœ¨ 3-1ë‹¨ê³„: evaluate í•¨ìˆ˜ ìˆ˜ì • âœ¨ ---
# criterionì„ ì¸ìë¡œ ë°›ë„ë¡ ë³€ê²½
def evaluate(model, loader, criterion, num_classes, device, device_type):
    model.eval(); freeze_bn_in_eval(model)
    f1_scorer = MulticlassF1Score(num_classes=num_classes, average='macro').to(device)

    running_loss, corrects, total = 0.0, 0, 0
    with torch.no_grad(), torch.autocast(device_type=device_type, dtype=torch.float16, enabled=(device_type=='cuda')):
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss = criterion(out, y) # ì „ë‹¬ë°›ì€ criterion ì‚¬ìš©
            _, pred = torch.max(out, 1)

            f1_scorer.update(pred, y)

            running_loss += loss.item() * x.size(0)
            corrects += torch.sum(pred == y).item()
            total += x.size(0)

    final_f1_score = f1_scorer.compute()
    return running_loss / total, corrects / total, final_f1_score.item()


# ==============================================================================
# ğŸƒ K-Fold Train/Val/Test Loop
# ==============================================================================
def main():
    cfg = Config()
    os.makedirs(cfg.OUTPUT_BASE, exist_ok=True)
    set_seed(cfg.SEED)
    print(f"Device: {cfg.DEVICE}")

    assert cfg.WARMUP_EPOCHS < cfg.NUM_EPOCHS, "WARMUP_EPOCHS must be < NUM_EPOCHS"

    fold_metrics = []

    for k in range(1, cfg.NUM_FOLDS + 1):
        print(f"\n==================== Fold {k}/{cfg.NUM_FOLDS} ====================")
        out_dir = os.path.join(cfg.OUTPUT_BASE, f"fold_{k}")
        os.makedirs(out_dir, exist_ok=True)

        loaders, datasets_dict, num_classes, class_names = get_dataloaders_for_fold(
            cfg.FOLDS_DIR, k, cfg.TEST_DIR, cfg.BATCH_SIZE, cfg.DEVICE.type
        )
        print(f"Classes ({num_classes}): {class_names}")

        model = build_lora_resnet50(num_classes, cfg.BASE_MODEL_PATH, cfg.DEVICE, cfg)
        base_model = model.get_base_model()
        fc_params   = list(base_model.fc.parameters())
        lora_params = [p for n,p in model.named_parameters() if ("lora_" in n) and p.requires_grad]

        optimizer = optim.AdamW([
            {"params": fc_params,   "lr": cfg.FC_LR},
            {"params": lora_params, "lr": cfg.LORA_LR},
        ], weight_decay=cfg.WEIGHT_DECAY)

        warmup = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=cfg.WARMUP_EPOCHS)
        cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.NUM_EPOCHS - cfg.WARMUP_EPOCHS)
        scheduler = optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[cfg.WARMUP_EPOCHS])

        # --- âœ¨ 3-2ë‹¨ê³„: FocalLoss ìƒì„± âœ¨ ---
        # í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ìœ„í•œ ê°€ì¤‘ì¹˜(alpha) ê³„ì‚°
        train_dataset = datasets_dict['train']
        class_counts = np.array([len(np.where(np.array(train_dataset.targets) == i)[0]) for i in range(num_classes)])
        class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)
        class_weights = class_weights / class_weights.sum()

        print("Calculated Class Weights (alpha):", class_weights)

        # Focal Lossë¥¼ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©
        criterion = FocalLoss(alpha=class_weights.to(cfg.DEVICE), gamma=cfg.FOCAL_GAMMA)
        scaler = torch.cuda.amp.GradScaler(enabled=(cfg.DEVICE.type=='cuda'))

        best_acc = 0.0
        for epoch in range(cfg.NUM_EPOCHS):
            print(f"\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}")
            cur_lrs = [pg['lr'] for pg in optimizer.param_groups]
            print("LRs:", ", ".join([f"{lr:.6f}" for lr in cur_lrs]))

            model.train(); freeze_bn_in_eval(model)
            run_loss, run_corrects, total = 0.0, 0, 0
            for x, y in tqdm(loaders['train'], desc="Train"):
                x, y = x.to(cfg.DEVICE), y.to(cfg.DEVICE)
                optimizer.zero_grad(set_to_none=True)
                with torch.autocast(device_type=cfg.DEVICE.type, dtype=torch.float16, enabled=(cfg.DEVICE.type=='cuda')):
                    out = model(x)
                    loss = criterion(out, y)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()

                _, pred = torch.max(out, 1)
                run_loss += loss.item() * x.size(0)
                run_corrects += torch.sum(pred == y).item()
                total += x.size(0)
            train_loss = run_loss / total
            train_acc  = run_corrects / total

            # --- âœ¨ 3-3ë‹¨ê³„: evaluate í˜¸ì¶œ ìˆ˜ì • âœ¨ ---
            # criterion ì „ë‹¬
            val_loss, val_acc, val_f1 = evaluate(model, loaders['val'], criterion, num_classes, cfg.DEVICE, cfg.DEVICE.type)
            print(f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}")

            if val_acc > best_acc:
                best_acc = val_acc
                print(f"New best val Acc: {best_acc:.4f} â†’ saving LoRA adapters to {out_dir}")
                model.save_pretrained(out_dir)

            scheduler.step()

        print("\n[Fold Final] Load best adapters and evaluate on TEST")
        base_for_merge = model.get_base_model().to('cpu')
        best_model = PeftModel.from_pretrained(base_for_merge, out_dir)

        # --- âœ¨ 3-4ë‹¨ê³„: ìµœì¢… evaluate í˜¸ì¶œ ìˆ˜ì • âœ¨ ---
        # criterion ì „ë‹¬
        test_loss, test_acc, test_f1 = evaluate(best_model.to(cfg.DEVICE), loaders['test'], criterion, num_classes, cfg.DEVICE, cfg.DEVICE.type)
        print(f"[Fold {k}] Test Loss: {test_loss:.4f} Acc: {test_acc:.4f} F1: {test_f1:.4f}")

        merged = best_model.merge_and_unload()
        merged_path = os.path.join(out_dir, "final_merged_model.pth")
        torch.save(merged.state_dict(), merged_path)
        print(f"[Fold {k}] âœ… Merged model saved to: {merged_path}")

        fold_metrics.append({"fold": k, "val_best_acc": best_acc, "test_acc": test_acc, "test_f1": test_f1})

    print("\n==================== K-Fold Summary ====================")
    for m in fold_metrics:
        print(f"Fold {m['fold']}: best Val Acc = {m['val_best_acc']:.4f}, Test Acc = {m['test_acc']:.4f}, Test F1 = {m['test_f1']:.4f}")

    mean_test_acc = np.mean([m["test_acc"] for m in fold_metrics])
    std_test_acc  = np.std([m["test_acc"] for m in fold_metrics])
    mean_test_f1 = np.mean([m["test_f1"] for m in fold_metrics])
    std_test_f1  = np.std([m["test_f1"] for m in fold_metrics])

    print(f"\nK={Config.NUM_FOLDS} Test Acc: mean = {mean_test_acc:.4f}, std = {std_test_acc:.4f}")
    print(f"K={Config.NUM_FOLDS} Test F1 : mean = {mean_test_f1:.4f}, std = {std_test_f1:.4f}")
    print("========================================================")

if __name__ == "__main__":
    main()

import os
import glob
from PIL import Image
import imagehash # ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ë‹¤ë©´ pip install imagehash
import shutil
from tqdm import tqdm

# ==============================================================================
# âš™ï¸ ì„¤ì • (Configuration) - ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ==============================================================================

# 1. ì¤‘ë³µì„ ì œê±°í•  ì›ë³¸ ì´ë¯¸ì§€ê°€ í´ë˜ìŠ¤ë³„ë¡œ ì •ë¦¬ëœ í´ë”
SOURCE_DIR = "./ROSE_Dataset/For_KFOLDS"

# 2. ì¤‘ë³µìœ¼ë¡œ ì˜ì‹¬ë˜ëŠ” ì´ë¯¸ì§€ë“¤ì„ ì˜®ê²¨ë†“ì„ í´ë” (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
QUARANTINE_DIR = "./quarantined_duplicates_ROSE_Dataset"

# 3. ìœ ì‚¬ë„ ì„ê³„ê°’ (í•´ì‹œì˜ ì°¨ì´). ìˆ«ìê°€ ì‘ì„ìˆ˜ë¡ ë” ì—„ê²©í•˜ê²Œ ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
#    0ì´ë©´ í”½ì…€ê¹Œì§€ ê±°ì˜ ì™„ë²½í•˜ê²Œ ë™ì¼í•œ ì´ë¯¸ì§€, 5 ì´í•˜ë©´ ìœ¡ì•ˆìœ¼ë¡œ êµ¬ë³„ í˜ë“  ì´ë¯¸ì§€.
SIMILARITY_THRESHOLD = 5

# ==============================================================================

def find_and_quarantine_duplicates(source_dir, quarantine_dir, threshold=5):
    """
    ì§€ì •ëœ í´ë” ë‚´ì—ì„œ ì¤‘ë³µ/ìœ ì‚¬ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ ê²©ë¦¬ í´ë”ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.
    """
    print("ì´ë¯¸ì§€ í•´ì‹œë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    os.makedirs(quarantine_dir, exist_ok=True)

    # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘
    image_paths = glob.glob(os.path.join(source_dir, "**", "*.jpg"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.jpeg"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.png"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.JPG"), recursive=True)

    # ê° ì´ë¯¸ì§€ì˜ í•´ì‹œ ê³„ì‚°
    hashes = {}
    for img_path in tqdm(image_paths, desc="Calculating Hashes"):
        try:
            with Image.open(img_path) as img:
                # pHash ì‚¬ìš© (ë‚´ìš© ê¸°ë°˜ í•´ì‹œ)
                img_hash = imagehash.phash(img)
                if img_hash in hashes:
                    hashes[img_hash].append(img_path)
                else:
                    hashes[img_hash] = [img_path]
        except Exception as e:
            print(f"ì˜¤ë¥˜: {img_path} íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")

    # 1. ì™„ë²½í•˜ê²Œ ë™ì¼í•œ í•´ì‹œë¥¼ ê°€ì§„ ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬
    exact_duplicates_found = 0
    print("\nì™„ë²½íˆ ë™ì¼í•œ ì¤‘ë³µ ì´ë¯¸ì§€ë¥¼ ì°¾ê³  ê²©ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    files_to_move = set()
    for hash_val, file_list in tqdm(hashes.items(), desc="Finding Exact Duplicates"):
        if len(file_list) > 1:
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ê³ , ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ ê²©ë¦¬ ëŒ€ìƒì— ì¶”ê°€
            files_to_move.update(file_list[1:])
            exact_duplicates_found += len(file_list) - 1

    # 2. ìœ ì‚¬í•œ í•´ì‹œë¥¼ ê°€ì§„ ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬
    similar_duplicates_found = 0
    print("\nìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ê³  ê²©ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")
    hash_list = list(hashes.keys())

    # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì€ ì œì™¸í•˜ê³  ë‚¨ì€ íŒŒì¼ ëª©ë¡ ìƒì„±
    remaining_files = [f for files in hashes.values() for f in files if f not in files_to_move]
    remaining_hashes = {imagehash.phash(Image.open(f)): f for f in remaining_files}
    hash_keys = list(remaining_hashes.keys())

    # ìœ ì‚¬ë„ ë¹„êµ
    for i in tqdm(range(len(hash_keys)), desc="Comparing Similar Images"):
        for j in range(i + 1, len(hash_keys)):
            hash1 = hash_keys[i]
            hash2 = hash_keys[j]

            if hash1 - hash2 <= threshold:
                # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ê²©ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì¶”ê°€
                filepath_to_move = remaining_hashes[hash2]
                if filepath_to_move not in files_to_move:
                    files_to_move.add(filepath_to_move)
                    similar_duplicates_found += 1

    # 3. íŒŒì¼ ì´ë™ ì‹¤í–‰
    print(f"\nì´ {len(files_to_move)}ê°œì˜ ì¤‘ë³µ/ìœ ì‚¬ íŒŒì¼ì„ ê²©ë¦¬ í´ë”ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
    for file_path in files_to_move:
        try:
            dest_path = os.path.join(quarantine_dir, os.path.basename(file_path))
            shutil.move(file_path, dest_path)
        except Exception as e:
            print(f"ì˜¤ë¥˜: {file_path} ì´ë™ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")

    print(f"\nâœ… ë°ì´í„° í´ë¦¬ë‹ ì™„ë£Œ!")
    print(f" - ì™„ë²½í•œ ì¤‘ë³µ: {exact_duplicates_found}ê°œ ë°œê²¬")
    print(f" - ìœ ì‚¬ ì´ë¯¸ì§€: {similar_duplicates_found}ê°œ ë°œê²¬")
    print(f" - ì´ {len(files_to_move)}ê°œì˜ íŒŒì¼ì´ '{quarantine_dir}' í´ë”ë¡œ ê²©ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ê²©ë¦¬ëœ íŒŒì¼ì„ í™•ì¸ í›„, ë¶ˆí•„ìš”í•˜ë‹¤ë©´ ì§ì ‘ ì‚­ì œí•´ì£¼ì„¸ìš”.")


if __name__ == '__main__':
    # imagehash ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
    try:
        import imagehash
    except ImportError:
        print("imagehash ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. 'pip install imagehash' ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        exit()

    find_and_quarantine_duplicates(SOURCE_DIR, QUARANTINE_DIR, threshold=SIMILARITY_THRESHOLD)

import os
import glob
import random
import shutil
from sklearn.model_selection import StratifiedKFold
from tqdm import tqdm
import numpy as np

# ==============================================================================
# âš™ï¸ ì„¤ì • (Configuration) - ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ==============================================================================

# 1. ëª¨ë“  ì›ë³¸ ì´ë¯¸ì§€ê°€ í´ë˜ìŠ¤ë³„ë¡œ ì •ë¦¬ëœ ìµœìƒìœ„ í´ë” ê²½ë¡œ
#    (ì´ í´ë” ì•ˆì— 'Canker', 'Normal' ë“± í´ë˜ìŠ¤ í´ë”ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)
SOURCE_DIR = "./ROSE_Dataset/For_KFOLDS"

# 2. K-Fold ë¶„í•  ê²°ê³¼ë¥¼ ì €ì¥í•  ìƒˆë¡œìš´ ê²½ë¡œ
DEST_DIR = "./ROSE_Dataset_KFOLDS"

# 3. ìƒì„±í•  Foldì˜ ê°œìˆ˜ (K)
NUM_FOLDS = 6

# 4. ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ
RANDOM_SEED = 42

# ==============================================================================

def create_stratified_k_folds(source_dir, dest_dir, k=5, seed=42):
    """
    ì›ë³¸ ì´ë¯¸ì§€ í´ë”ë¥¼ ê³„ì¸µì  K-Foldë¡œ ë¶„í• í•˜ì—¬ ìƒˆë¡œìš´ í´ë” êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("ë°ì´í„° ë¶„í• ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(dest_dir, exist_ok=True)

    # 1. ëª¨ë“  ì´ë¯¸ì§€ ê²½ë¡œì™€ í´ë˜ìŠ¤ ë¼ë²¨ ìˆ˜ì§‘
    filepaths = []
    labels = []

    class_dirs = sorted([d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))])
    label_map = {class_name: i for i, class_name in enumerate(class_dirs)}

    print(f"{len(class_dirs)}ê°œì˜ í´ë˜ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {class_dirs}")

    for class_name in class_dirs:
        class_path = os.path.join(source_dir, class_name)
        # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼(jpg, jpeg, png) ê²€ìƒ‰
        images = glob.glob(os.path.join(class_path, "*.jpg")) + \
                 glob.glob(os.path.join(class_path, "*.jpeg")) + \
                 glob.glob(os.path.join(class_path, "*.png")) + \
                 glob.glob(os.path.join(class_path, "*.JPG")) + \
                 glob.glob(os.path.join(class_path, "*.JPEG")) + \
                 glob.glob(os.path.join(class_path, "*.PNG"))

        for img_path in images:
            filepaths.append(img_path)
            labels.append(label_map[class_name])

    filepaths = np.array(filepaths)
    labels = np.array(labels)

    print(f"ì´ {len(filepaths)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")

    # 2. StratifiedKFoldë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ ë¶„í• 
    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)

    fold_num = 1
    # skf.splitì€ (train_indices, val_indices)ë¥¼ ìƒì„±í•´ì¤Œ
    for train_idx, val_idx in tqdm(skf.split(filepaths, labels), total=k, desc="Creating Folds"):
        fold_dir = os.path.join(dest_dir, f"fold_{fold_num}")
        train_dir = os.path.join(fold_dir, "train")
        val_dir = os.path.join(fold_dir, "val")

        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(val_dir, exist_ok=True)

        # ê° í´ë˜ìŠ¤ë³„ í´ë” ìƒì„±
        for class_name in class_dirs:
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)

        # 3. ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•´ íŒŒì¼ ë³µì‚¬
        # Validation ë°ì´í„° ë³µì‚¬
        for i in val_idx:
            src_path = filepaths[i]
            class_name = os.path.basename(os.path.dirname(src_path))
            dest_path = os.path.join(val_dir, class_name, os.path.basename(src_path))
            shutil.copyfile(src_path, dest_path)

        # Training ë°ì´í„° ë³µì‚¬
        for i in train_idx:
            src_path = filepaths[i]
            class_name = os.path.basename(os.path.dirname(src_path))
            dest_path = os.path.join(train_dir, class_name, os.path.basename(src_path))
            shutil.copyfile(src_path, dest_path)

        print(f"Fold {fold_num}: Train {len(train_idx)}ê°œ, Val {len(val_idx)}ê°œ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ.")
        fold_num += 1

    print(f"\nâœ… {k}-Fold ë°ì´í„° ë¶„í• ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” '{dest_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == '__main__':
    create_stratified_k_folds(SOURCE_DIR, DEST_DIR, k=NUM_FOLDS, seed=RANDOM_SEED)

import os
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import glob

# =====================================================================
# âš™ï¸ ì„¤ì • (Configuration)
# =====================================================================

BASE_INPUT_DIR = "./ROSE_Dataset_KFOLDS"
BASE_OUTPUT_DIR = "./ROSE_Dataset_KFOLDS_augmented"
FOLD_RANGE = range(1, 7)  # fold_1 ~ fold_10
NUM_AUGMENTATIONS_PER_IMAGE = 4

# =====================================================================

def augment_and_save_images(input_base_dir, output_base_dir, num_augmentations):
    augmentation_pipeline = transforms.Compose([
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.TrivialAugmentWide(num_magnitude_bins=31),
    ])

    print(f"'{input_base_dir}'ì˜ ì´ë¯¸ì§€ ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"ê²°ê³¼ëŠ” '{output_base_dir}'ì— ì €ì¥ë©ë‹ˆë‹¤.")
    print(f"ì´ë¯¸ì§€ë‹¹ {num_augmentations}ê°œì˜ ì¦ê°• ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    class_dirs = [d for d in os.listdir(input_base_dir) if os.path.isdir(os.path.join(input_base_dir, d))]

    if not class_dirs:
        print(f"ì˜¤ë¥˜: '{input_base_dir}'ì—ì„œ í´ë˜ìŠ¤ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    for class_name in tqdm(class_dirs, desc="Overall Progress"):
        input_class_path = os.path.join(input_base_dir, class_name)
        output_class_path = os.path.join(output_base_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        image_paths = glob.glob(os.path.join(input_class_path, "*.jpg")) + \
                      glob.glob(os.path.join(input_class_path, "*.jpeg")) + \
                      glob.glob(os.path.join(input_class_path, "*.png")) + \
                      glob.glob(os.path.join(input_class_path, "*.JPG")) + \
                      glob.glob(os.path.join(input_class_path, "*.JPEG")) + \
                      glob.glob(os.path.join(input_class_path, "*.PNG"))

        for img_path in tqdm(image_paths, desc=f"Processing {class_name}", leave=False):
            try:
                img = Image.open(img_path).convert("RGB")
                base_filename, extension = os.path.splitext(os.path.basename(img_path))
                original_save_path = os.path.join(output_class_path, os.path.basename(img_path))
                img.save(original_save_path)

                for i in range(num_augmentations):
                    augmented_img = augmentation_pipeline(img)
                    new_filename = f"{base_filename}_aug_{i+1}{extension}"
                    save_path = os.path.join(output_class_path, new_filename)
                    augmented_img.save(save_path)

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {img_path} ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ - {e}")

    print("\nâœ… ì´ë¯¸ì§€ ì¦ê°• ë° ì €ì¥ ì™„ë£Œ!")

# =====================================================================
# ğŸ” ëª¨ë“  Foldì— ëŒ€í•´ ìë™ ì²˜ë¦¬
# =====================================================================

if __name__ == '__main__':
    for fold_num in FOLD_RANGE:
        input_dir = os.path.join(BASE_INPUT_DIR, f"fold_{fold_num}", "train")
        output_dir = os.path.join(BASE_OUTPUT_DIR, f"fold_{fold_num}", "train")
        augment_and_save_images(input_dir, output_dir, NUM_AUGMENTATIONS_PER_IMAGE)