# -*- coding: utf-8 -*-
"""LoRA_finetuning.ipynbÏùò ÏÇ¨Î≥∏Ïùò ÏÇ¨Î≥∏

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iZhJ1RGOxs0TRHxjhB1idnMkG9xSyYya
"""

!pip install torch torchvision tqdm peft accelerate transformers numpy imagehash

pip install scikit-learn

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms, datasets
from peft import LoraConfig, get_peft_model, TaskType, PeftModel
import os
import random
import numpy as np
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

# lora_kfold_train.py
import os
import random
import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F # <-- FocalLossÎ•º ÏúÑÌï¥ Ï∂îÍ∞Ä
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models, transforms, datasets
from peft import LoraConfig, get_peft_model, TaskType, PeftModel
from torchmetrics.classification import MulticlassF1Score

# ==============================================================================
# ‚öôÔ∏è CONFIG
# ==============================================================================
class Config:
    FOLDS_DIR = "./ROSE_Dataset_KFOLDS"
    NUM_FOLDS = 6
    TEST_DIR = "./ROSE_Dataset/test"
    BASE_MODEL_PATH = "./plant-model-epoch=39-val_f1=0.922.ckpt"
    OUTPUT_BASE = "./LoRA_OUTPUT_Rose"
    SEED = 42
    NUM_EPOCHS = 20
    BATCH_SIZE = 32
    WEIGHT_DECAY = 0.05
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    WARMUP_EPOCHS = 2
    FC_LR = 5e-4
    LORA_LR = 1e-4
    LORA_R = 16
    LORA_ALPHA = 32
    LORA_DROPOUT = 0.2
    # --- ‚ú® Ï∂îÍ∞ÄÎêú ÏÑ§Ï†ï: Focal Loss Í∞êÎßà Í∞í ---
    FOCAL_GAMMA = 2.0

# ==============================================================================
# üîß UTILS
# ==============================================================================

# <-- ‚ú® 1Îã®Í≥Ñ: FocalLoss ÌÅ¥ÎûòÏä§ Ï∂îÍ∞Ä ‚ú® -->
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        if self.alpha is not None:
            alpha_t = self.alpha[targets]
            focal_loss = alpha_t * (1 - pt)**self.gamma * ce_loss
        else:
            focal_loss = (1 - pt)**self.gamma * ce_loss
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

def set_seed(seed: int):
    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.benchmark = True

def print_trainable_parameters(model):
    t, a = 0, 0
    for _, p in model.named_parameters():
        a += p.numel()
        if p.requires_grad: t += p.numel()
    print(f"trainable params: {t} || all params: {a} || trainable%: {100*t/a:.2f}")

def freeze_bn_in_eval(model):
    for m in model.modules():
        if isinstance(m, nn.BatchNorm2d):
            m.eval()

def get_dataloaders_for_fold(FOLDS_DIR, fold_idx, TEST_DIR, batch_size, device_type):
    fold_base_dir = os.path.join(FOLDS_DIR, f"fold_{fold_idx}")
    train_dir = os.path.join(fold_base_dir, "train")
    val_dir   = os.path.join(fold_base_dir, "val")
    test_dir  = TEST_DIR

    tfm = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
        ]),
        'val_test': transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
        ]),
    }

    image_datasets = {
        'train': datasets.ImageFolder(train_dir, tfm['train']),
        'val'  : datasets.ImageFolder(val_dir,   tfm['val_test']),
        'test' : datasets.ImageFolder(test_dir,  tfm['val_test']),
    }

    dataloaders = {
        'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True,
                            num_workers=2, pin_memory=(device_type=='cuda')),
        'val'  : DataLoader(image_datasets['val'],   batch_size=batch_size, shuffle=False,
                            num_workers=2, pin_memory=(device_type=='cuda')),
        'test' : DataLoader(image_datasets['test'],  batch_size=batch_size, shuffle=False,
                            num_workers=2, pin_memory=(device_type=='cuda')),
    }
    num_classes = len(image_datasets['train'].classes)
    class_names = image_datasets['train'].classes
    return dataloaders, image_datasets, num_classes, class_names

def build_lora_resnet50(num_classes, base_model_path, device, cfg: Config):
    model = models.resnet50(weights=None)
    in_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(p=0.4),
        nn.Linear(in_features, num_classes)
    )

    for n, p in model.named_parameters():
        p.requires_grad = n.startswith("fc.")

    try:
        checkpoint = torch.load(base_model_path, map_location="cpu", weights_only=False)
        state_dict = checkpoint.get("state_dict", checkpoint)
        cleaned_state_dict = {k.replace("resnet.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(cleaned_state_dict, strict=False)
        print("Base model weights loaded successfully.")
    except Exception as e:
        print(f"Could not load base model weights: {e} (continue).")

    conv_targets = [name for name, m in model.named_modules() if isinstance(m, nn.Conv2d)]
    lora_conf = LoraConfig(
        r=cfg.LORA_R, lora_alpha=cfg.LORA_ALPHA, lora_dropout=cfg.LORA_DROPOUT,
        target_modules=conv_targets, bias="none"
    )
    model = get_peft_model(model, lora_conf)
    print_trainable_parameters(model)
    return model.to(device)

# --- ‚ú® 3-1Îã®Í≥Ñ: evaluate Ìï®Ïàò ÏàòÏ†ï ‚ú® ---
# criterionÏùÑ Ïù∏ÏûêÎ°ú Î∞õÎèÑÎ°ù Î≥ÄÍ≤Ω
def evaluate(model, loader, criterion, num_classes, device, device_type):
    model.eval(); freeze_bn_in_eval(model)
    f1_scorer = MulticlassF1Score(num_classes=num_classes, average='macro').to(device)

    running_loss, corrects, total = 0.0, 0, 0
    with torch.no_grad(), torch.autocast(device_type=device_type, dtype=torch.float16, enabled=(device_type=='cuda')):
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss = criterion(out, y) # Ï†ÑÎã¨Î∞õÏùÄ criterion ÏÇ¨Ïö©
            _, pred = torch.max(out, 1)

            f1_scorer.update(pred, y)

            running_loss += loss.item() * x.size(0)
            corrects += torch.sum(pred == y).item()
            total += x.size(0)

    final_f1_score = f1_scorer.compute()
    return running_loss / total, corrects / total, final_f1_score.item()


# ==============================================================================
# üèÉ K-Fold Train/Val/Test Loop
# ==============================================================================
def main():
    cfg = Config()
    os.makedirs(cfg.OUTPUT_BASE, exist_ok=True)
    set_seed(cfg.SEED)
    print(f"Device: {cfg.DEVICE}")

    assert cfg.WARMUP_EPOCHS < cfg.NUM_EPOCHS, "WARMUP_EPOCHS must be < NUM_EPOCHS"

    fold_metrics = []

    for k in range(1, cfg.NUM_FOLDS + 1):
        print(f"\n==================== Fold {k}/{cfg.NUM_FOLDS} ====================")
        out_dir = os.path.join(cfg.OUTPUT_BASE, f"fold_{k}")
        os.makedirs(out_dir, exist_ok=True)

        loaders, datasets_dict, num_classes, class_names = get_dataloaders_for_fold(
            cfg.FOLDS_DIR, k, cfg.TEST_DIR, cfg.BATCH_SIZE, cfg.DEVICE.type
        )
        print(f"Classes ({num_classes}): {class_names}")

        model = build_lora_resnet50(num_classes, cfg.BASE_MODEL_PATH, cfg.DEVICE, cfg)
        base_model = model.get_base_model()
        fc_params   = list(base_model.fc.parameters())
        lora_params = [p for n,p in model.named_parameters() if ("lora_" in n) and p.requires_grad]

        optimizer = optim.AdamW([
            {"params": fc_params,   "lr": cfg.FC_LR},
            {"params": lora_params, "lr": cfg.LORA_LR},
        ], weight_decay=cfg.WEIGHT_DECAY)

        warmup = optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=cfg.WARMUP_EPOCHS)
        cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.NUM_EPOCHS - cfg.WARMUP_EPOCHS)
        scheduler = optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[cfg.WARMUP_EPOCHS])

        # --- ‚ú® 3-2Îã®Í≥Ñ: FocalLoss ÏÉùÏÑ± ‚ú® ---
        # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†ÌòïÏùÑ ÏúÑÌïú Í∞ÄÏ§ëÏπò(alpha) Í≥ÑÏÇ∞
        train_dataset = datasets_dict['train']
        class_counts = np.array([len(np.where(np.array(train_dataset.targets) == i)[0]) for i in range(num_classes)])
        class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)
        class_weights = class_weights / class_weights.sum()

        print("Calculated Class Weights (alpha):", class_weights)

        # Focal LossÎ•º ÏÜêÏã§ Ìï®ÏàòÎ°ú ÏÇ¨Ïö©
        criterion = FocalLoss(alpha=class_weights.to(cfg.DEVICE), gamma=cfg.FOCAL_GAMMA)
        scaler = torch.cuda.amp.GradScaler(enabled=(cfg.DEVICE.type=='cuda'))

        best_acc = 0.0
        for epoch in range(cfg.NUM_EPOCHS):
            print(f"\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}")
            cur_lrs = [pg['lr'] for pg in optimizer.param_groups]
            print("LRs:", ", ".join([f"{lr:.6f}" for lr in cur_lrs]))

            model.train(); freeze_bn_in_eval(model)
            run_loss, run_corrects, total = 0.0, 0, 0
            for x, y in tqdm(loaders['train'], desc="Train"):
                x, y = x.to(cfg.DEVICE), y.to(cfg.DEVICE)
                optimizer.zero_grad(set_to_none=True)
                with torch.autocast(device_type=cfg.DEVICE.type, dtype=torch.float16, enabled=(cfg.DEVICE.type=='cuda')):
                    out = model(x)
                    loss = criterion(out, y)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()

                _, pred = torch.max(out, 1)
                run_loss += loss.item() * x.size(0)
                run_corrects += torch.sum(pred == y).item()
                total += x.size(0)
            train_loss = run_loss / total
            train_acc  = run_corrects / total

            # --- ‚ú® 3-3Îã®Í≥Ñ: evaluate Ìò∏Ï∂ú ÏàòÏ†ï ‚ú® ---
            # criterion Ï†ÑÎã¨
            val_loss, val_acc, val_f1 = evaluate(model, loaders['val'], criterion, num_classes, cfg.DEVICE, cfg.DEVICE.type)
            print(f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}")

            if val_acc > best_acc:
                best_acc = val_acc
                print(f"New best val Acc: {best_acc:.4f} ‚Üí saving LoRA adapters to {out_dir}")
                model.save_pretrained(out_dir)

            scheduler.step()

        print("\n[Fold Final] Load best adapters and evaluate on TEST")
        base_for_merge = model.get_base_model().to('cpu')
        best_model = PeftModel.from_pretrained(base_for_merge, out_dir)

        # --- ‚ú® 3-4Îã®Í≥Ñ: ÏµúÏ¢Ö evaluate Ìò∏Ï∂ú ÏàòÏ†ï ‚ú® ---
        # criterion Ï†ÑÎã¨
        test_loss, test_acc, test_f1 = evaluate(best_model.to(cfg.DEVICE), loaders['test'], criterion, num_classes, cfg.DEVICE, cfg.DEVICE.type)
        print(f"[Fold {k}] Test Loss: {test_loss:.4f} Acc: {test_acc:.4f} F1: {test_f1:.4f}")

        merged = best_model.merge_and_unload()
        merged_path = os.path.join(out_dir, "final_merged_model.pth")
        torch.save(merged.state_dict(), merged_path)
        print(f"[Fold {k}] ‚úÖ Merged model saved to: {merged_path}")

        fold_metrics.append({"fold": k, "val_best_acc": best_acc, "test_acc": test_acc, "test_f1": test_f1})

    print("\n==================== K-Fold Summary ====================")
    for m in fold_metrics:
        print(f"Fold {m['fold']}: best Val Acc = {m['val_best_acc']:.4f}, Test Acc = {m['test_acc']:.4f}, Test F1 = {m['test_f1']:.4f}")

    mean_test_acc = np.mean([m["test_acc"] for m in fold_metrics])
    std_test_acc  = np.std([m["test_acc"] for m in fold_metrics])
    mean_test_f1 = np.mean([m["test_f1"] for m in fold_metrics])
    std_test_f1  = np.std([m["test_f1"] for m in fold_metrics])

    print(f"\nK={Config.NUM_FOLDS} Test Acc: mean = {mean_test_acc:.4f}, std = {std_test_acc:.4f}")
    print(f"K={Config.NUM_FOLDS} Test F1 : mean = {mean_test_f1:.4f}, std = {std_test_f1:.4f}")
    print("========================================================")

if __name__ == "__main__":
    main()

import os
import glob
from PIL import Image
import imagehash # Ïù¥ ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏóÜÎã§Î©¥ pip install imagehash
import shutil
from tqdm import tqdm

# ==============================================================================
# ‚öôÔ∏è ÏÑ§Ï†ï (Configuration) - Ïù¥ Î∂ÄÎ∂ÑÎßå ÏàòÏ†ïÌïòÏÑ∏Ïöî!
# ==============================================================================

# 1. Ï§ëÎ≥µÏùÑ Ï†úÍ±∞Ìï† ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÌÅ¥ÎûòÏä§Î≥ÑÎ°ú Ï†ïÎ¶¨Îêú Ìè¥Îçî
SOURCE_DIR = "./ROSE_Dataset/For_KFOLDS"

# 2. Ï§ëÎ≥µÏúºÎ°ú ÏùòÏã¨ÎêòÎäî Ïù¥ÎØ∏ÏßÄÎì§ÏùÑ ÏòÆÍ≤®ÎÜìÏùÑ Ìè¥Îçî (ÏóÜÏúºÎ©¥ ÏûêÎèô ÏÉùÏÑ±)
QUARANTINE_DIR = "./quarantined_duplicates_ROSE_Dataset"

# 3. Ïú†ÏÇ¨ÎèÑ ÏûÑÍ≥ÑÍ∞í (Ìï¥ÏãúÏùò Ï∞®Ïù¥). Ïà´ÏûêÍ∞Ä ÏûëÏùÑÏàòÎ°ù Îçî ÏóÑÍ≤©ÌïòÍ≤å ÎèôÏùºÌïú Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏäµÎãàÎã§.
#    0Ïù¥Î©¥ ÌîΩÏÖÄÍπåÏßÄ Í±∞Ïùò ÏôÑÎ≤ΩÌïòÍ≤å ÎèôÏùºÌïú Ïù¥ÎØ∏ÏßÄ, 5 Ïù¥ÌïòÎ©¥ Ïú°ÏïàÏúºÎ°ú Íµ¨Î≥Ñ ÌûòÎì† Ïù¥ÎØ∏ÏßÄ.
SIMILARITY_THRESHOLD = 5

# ==============================================================================

def find_and_quarantine_duplicates(source_dir, quarantine_dir, threshold=5):
    """
    ÏßÄÏ†ïÎêú Ìè¥Îçî ÎÇ¥ÏóêÏÑú Ï§ëÎ≥µ/Ïú†ÏÇ¨ Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏïÑ Í≤©Î¶¨ Ìè¥ÎçîÎ°ú Ïù¥ÎèôÏãúÌÇµÎãàÎã§.
    """
    print("Ïù¥ÎØ∏ÏßÄ Ìï¥ÏãúÎ•º Í≥ÑÏÇ∞ÌïòÎäî Ï§ëÏûÖÎãàÎã§...")
    os.makedirs(quarantine_dir, exist_ok=True)

    # Î™®Îì† Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú ÏàòÏßë
    image_paths = glob.glob(os.path.join(source_dir, "**", "*.jpg"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.jpeg"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.png"), recursive=True) + \
                  glob.glob(os.path.join(source_dir, "**", "*.JPG"), recursive=True)

    # Í∞Å Ïù¥ÎØ∏ÏßÄÏùò Ìï¥Ïãú Í≥ÑÏÇ∞
    hashes = {}
    for img_path in tqdm(image_paths, desc="Calculating Hashes"):
        try:
            with Image.open(img_path) as img:
                # pHash ÏÇ¨Ïö© (ÎÇ¥Ïö© Í∏∞Î∞ò Ìï¥Ïãú)
                img_hash = imagehash.phash(img)
                if img_hash in hashes:
                    hashes[img_hash].append(img_path)
                else:
                    hashes[img_hash] = [img_path]
        except Exception as e:
            print(f"Ïò§Î•ò: {img_path} ÌååÏùºÏùÑ Ïó¨Îäî Ï§ë Î¨∏Ï†ú Î∞úÏÉù - {e}")

    # 1. ÏôÑÎ≤ΩÌïòÍ≤å ÎèôÏùºÌïú Ìï¥ÏãúÎ•º Í∞ÄÏßÑ Ï§ëÎ≥µ ÌååÏùº Ï≤òÎ¶¨
    exact_duplicates_found = 0
    print("\nÏôÑÎ≤ΩÌûà ÎèôÏùºÌïú Ï§ëÎ≥µ Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÍ≥† Í≤©Î¶¨ÌïòÎäî Ï§ëÏûÖÎãàÎã§...")
    files_to_move = set()
    for hash_val, file_list in tqdm(hashes.items(), desc="Finding Exact Duplicates"):
        if len(file_list) > 1:
            # Ï≤´ Î≤àÏß∏ ÌååÏùºÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÏÇºÍ≥†, ÎÇòÎ®∏ÏßÄÎäî Î™®Îëê Í≤©Î¶¨ ÎåÄÏÉÅÏóê Ï∂îÍ∞Ä
            files_to_move.update(file_list[1:])
            exact_duplicates_found += len(file_list) - 1

    # 2. Ïú†ÏÇ¨Ìïú Ìï¥ÏãúÎ•º Í∞ÄÏßÑ Ï§ëÎ≥µ ÌååÏùº Ï≤òÎ¶¨
    similar_duplicates_found = 0
    print("\nÏú†ÏÇ¨Ìïú Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÍ≥† Í≤©Î¶¨ÌïòÎäî Ï§ëÏûÖÎãàÎã§ (ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)...")
    hash_list = list(hashes.keys())

    # Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú ÌååÏùºÏùÄ Ï†úÏô∏ÌïòÍ≥† ÎÇ®ÏùÄ ÌååÏùº Î™©Î°ù ÏÉùÏÑ±
    remaining_files = [f for files in hashes.values() for f in files if f not in files_to_move]
    remaining_hashes = {imagehash.phash(Image.open(f)): f for f in remaining_files}
    hash_keys = list(remaining_hashes.keys())

    # Ïú†ÏÇ¨ÎèÑ ÎπÑÍµê
    for i in tqdm(range(len(hash_keys)), desc="Comparing Similar Images"):
        for j in range(i + 1, len(hash_keys)):
            hash1 = hash_keys[i]
            hash2 = hash_keys[j]

            if hash1 - hash2 <= threshold:
                # Îëê Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎ•º Í≤©Î¶¨ ÎåÄÏÉÅÏúºÎ°ú Ï∂îÍ∞Ä
                filepath_to_move = remaining_hashes[hash2]
                if filepath_to_move not in files_to_move:
                    files_to_move.add(filepath_to_move)
                    similar_duplicates_found += 1

    # 3. ÌååÏùº Ïù¥Îèô Ïã§Ìñâ
    print(f"\nÏ¥ù {len(files_to_move)}Í∞úÏùò Ï§ëÎ≥µ/Ïú†ÏÇ¨ ÌååÏùºÏùÑ Í≤©Î¶¨ Ìè¥ÎçîÎ°ú Ïù¥ÎèôÌï©ÎãàÎã§.")
    for file_path in files_to_move:
        try:
            dest_path = os.path.join(quarantine_dir, os.path.basename(file_path))
            shutil.move(file_path, dest_path)
        except Exception as e:
            print(f"Ïò§Î•ò: {file_path} Ïù¥Îèô Ï§ë Î¨∏Ï†ú Î∞úÏÉù - {e}")

    print(f"\n‚úÖ Îç∞Ïù¥ÌÑ∞ ÌÅ¥Î¶¨Îãù ÏôÑÎ£å!")
    print(f" - ÏôÑÎ≤ΩÌïú Ï§ëÎ≥µ: {exact_duplicates_found}Í∞ú Î∞úÍ≤¨")
    print(f" - Ïú†ÏÇ¨ Ïù¥ÎØ∏ÏßÄ: {similar_duplicates_found}Í∞ú Î∞úÍ≤¨")
    print(f" - Ï¥ù {len(files_to_move)}Í∞úÏùò ÌååÏùºÏù¥ '{quarantine_dir}' Ìè¥ÎçîÎ°ú Í≤©Î¶¨ÎêòÏóàÏäµÎãàÎã§.")
    print("Í≤©Î¶¨Îêú ÌååÏùºÏùÑ ÌôïÏù∏ ÌõÑ, Î∂àÌïÑÏöîÌïòÎã§Î©¥ ÏßÅÏ†ë ÏÇ≠Ï†úÌï¥Ï£ºÏÑ∏Ïöî.")


if __name__ == '__main__':
    # imagehash ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò ÌôïÏù∏
    try:
        import imagehash
    except ImportError:
        print("imagehash ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§. 'pip install imagehash' Î™ÖÎ†πÏñ¥Î°ú ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî.")
        exit()

    find_and_quarantine_duplicates(SOURCE_DIR, QUARANTINE_DIR, threshold=SIMILARITY_THRESHOLD)

import os
import glob
import random
import shutil
from sklearn.model_selection import StratifiedKFold
from tqdm import tqdm
import numpy as np

# ==============================================================================
# ‚öôÔ∏è ÏÑ§Ï†ï (Configuration) - Ïù¥ Î∂ÄÎ∂ÑÎßå ÏàòÏ†ïÌïòÏÑ∏Ïöî!
# ==============================================================================

# 1. Î™®Îì† ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÌÅ¥ÎûòÏä§Î≥ÑÎ°ú Ï†ïÎ¶¨Îêú ÏµúÏÉÅÏúÑ Ìè¥Îçî Í≤ΩÎ°ú
#    (Ïù¥ Ìè¥Îçî ÏïàÏóê 'Canker', 'Normal' Îì± ÌÅ¥ÎûòÏä§ Ìè¥ÎçîÍ∞Ä ÏûàÏñ¥Ïïº Ìï©ÎãàÎã§)
SOURCE_DIR = "./ROSE_Dataset/For_KFOLDS"

# 2. K-Fold Î∂ÑÌï† Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† ÏÉàÎ°úÏö¥ Í≤ΩÎ°ú
DEST_DIR = "./ROSE_Dataset_KFOLDS"

# 3. ÏÉùÏÑ±Ìï† FoldÏùò Í∞úÏàò (K)
NUM_FOLDS = 6

# 4. Ïû¨ÌòÑÏÑ±ÏùÑ ÏúÑÌïú ÎûúÎç§ ÏãúÎìú
RANDOM_SEED = 42

# ==============================================================================

def create_stratified_k_folds(source_dir, dest_dir, k=5, seed=42):
    """
    ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Ìè¥ÎçîÎ•º Í≥ÑÏ∏µÏ†Å K-FoldÎ°ú Î∂ÑÌï†ÌïòÏó¨ ÏÉàÎ°úÏö¥ Ìè¥Îçî Íµ¨Ï°∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
    """
    print("Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†ÏùÑ ÏãúÏûëÌï©ÎãàÎã§...")
    # Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
    os.makedirs(dest_dir, exist_ok=True)

    # 1. Î™®Îì† Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÏôÄ ÌÅ¥ÎûòÏä§ ÎùºÎ≤® ÏàòÏßë
    filepaths = []
    labels = []

    class_dirs = sorted([d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))])
    label_map = {class_name: i for i, class_name in enumerate(class_dirs)}

    print(f"{len(class_dirs)}Í∞úÏùò ÌÅ¥ÎûòÏä§Î•º Î∞úÍ≤¨ÌñàÏäµÎãàÎã§: {class_dirs}")

    for class_name in class_dirs:
        class_path = os.path.join(source_dir, class_name)
        # Î™®Îì† Ïù¥ÎØ∏ÏßÄ ÌååÏùº(jpg, jpeg, png) Í≤ÄÏÉâ
        images = glob.glob(os.path.join(class_path, "*.jpg")) + \
                 glob.glob(os.path.join(class_path, "*.jpeg")) + \
                 glob.glob(os.path.join(class_path, "*.png")) + \
                 glob.glob(os.path.join(class_path, "*.JPG")) + \
                 glob.glob(os.path.join(class_path, "*.JPEG")) + \
                 glob.glob(os.path.join(class_path, "*.PNG"))

        for img_path in images:
            filepaths.append(img_path)
            labels.append(label_map[class_name])

    filepaths = np.array(filepaths)
    labels = np.array(labels)

    print(f"Ï¥ù {len(filepaths)}Í∞úÏùò Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùÑ ÏàòÏßëÌñàÏäµÎãàÎã§.")

    # 2. StratifiedKFoldÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïù∏Îç±Ïä§ Î∂ÑÌï†
    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)

    fold_num = 1
    # skf.splitÏùÄ (train_indices, val_indices)Î•º ÏÉùÏÑ±Ìï¥Ï§å
    for train_idx, val_idx in tqdm(skf.split(filepaths, labels), total=k, desc="Creating Folds"):
        fold_dir = os.path.join(dest_dir, f"fold_{fold_num}")
        train_dir = os.path.join(fold_dir, "train")
        val_dir = os.path.join(fold_dir, "val")

        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(val_dir, exist_ok=True)

        # Í∞Å ÌÅ¥ÎûòÏä§Î≥Ñ Ìè¥Îçî ÏÉùÏÑ±
        for class_name in class_dirs:
            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)
            os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)

        # 3. Ïù∏Îç±Ïä§Î•º ÏÇ¨Ïö©Ìï¥ ÌååÏùº Î≥µÏÇ¨
        # Validation Îç∞Ïù¥ÌÑ∞ Î≥µÏÇ¨
        for i in val_idx:
            src_path = filepaths[i]
            class_name = os.path.basename(os.path.dirname(src_path))
            dest_path = os.path.join(val_dir, class_name, os.path.basename(src_path))
            shutil.copyfile(src_path, dest_path)

        # Training Îç∞Ïù¥ÌÑ∞ Î≥µÏÇ¨
        for i in train_idx:
            src_path = filepaths[i]
            class_name = os.path.basename(os.path.dirname(src_path))
            dest_path = os.path.join(train_dir, class_name, os.path.basename(src_path))
            shutil.copyfile(src_path, dest_path)

        print(f"Fold {fold_num}: Train {len(train_idx)}Í∞ú, Val {len(val_idx)}Í∞ú Ïù¥ÎØ∏ÏßÄ Î≥µÏÇ¨ ÏôÑÎ£å.")
        fold_num += 1

    print(f"\n‚úÖ {k}-Fold Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§. Í≤∞Í≥ºÎäî '{dest_dir}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.")


if __name__ == '__main__':
    create_stratified_k_folds(SOURCE_DIR, DEST_DIR, k=NUM_FOLDS, seed=RANDOM_SEED)

import os
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import glob

# =====================================================================
# ‚öôÔ∏è ÏÑ§Ï†ï (Configuration)
# =====================================================================

BASE_INPUT_DIR = "./ROSE_Dataset_KFOLDS"
BASE_OUTPUT_DIR = "./ROSE_Dataset_KFOLDS_augmented"
FOLD_RANGE = range(1, 7)  # fold_1 ~ fold_10
NUM_AUGMENTATIONS_PER_IMAGE = 4

# =====================================================================

def augment_and_save_images(input_base_dir, output_base_dir, num_augmentations):
    augmentation_pipeline = transforms.Compose([
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.TrivialAugmentWide(num_magnitude_bins=31),
    ])

    print(f"'{input_base_dir}'Ïùò Ïù¥ÎØ∏ÏßÄ Ï¶ùÍ∞ïÏùÑ ÏãúÏûëÌï©ÎãàÎã§.")
    print(f"Í≤∞Í≥ºÎäî '{output_base_dir}'Ïóê Ï†ÄÏû•Îê©ÎãàÎã§.")
    print(f"Ïù¥ÎØ∏ÏßÄÎãπ {num_augmentations}Í∞úÏùò Ï¶ùÍ∞ï Ïù¥ÎØ∏ÏßÄÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.")

    class_dirs = [d for d in os.listdir(input_base_dir) if os.path.isdir(os.path.join(input_base_dir, d))]

    if not class_dirs:
        print(f"Ïò§Î•ò: '{input_base_dir}'ÏóêÏÑú ÌÅ¥ÎûòÏä§ Ìè¥ÎçîÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    for class_name in tqdm(class_dirs, desc="Overall Progress"):
        input_class_path = os.path.join(input_base_dir, class_name)
        output_class_path = os.path.join(output_base_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        image_paths = glob.glob(os.path.join(input_class_path, "*.jpg")) + \
                      glob.glob(os.path.join(input_class_path, "*.jpeg")) + \
                      glob.glob(os.path.join(input_class_path, "*.png")) + \
                      glob.glob(os.path.join(input_class_path, "*.JPG")) + \
                      glob.glob(os.path.join(input_class_path, "*.JPEG")) + \
                      glob.glob(os.path.join(input_class_path, "*.PNG"))

        for img_path in tqdm(image_paths, desc=f"Processing {class_name}", leave=False):
            try:
                img = Image.open(img_path).convert("RGB")
                base_filename, extension = os.path.splitext(os.path.basename(img_path))
                original_save_path = os.path.join(output_class_path, os.path.basename(img_path))
                img.save(original_save_path)

                for i in range(num_augmentations):
                    augmented_img = augmentation_pipeline(img)
                    new_filename = f"{base_filename}_aug_{i+1}{extension}"
                    save_path = os.path.join(output_class_path, new_filename)
                    augmented_img.save(save_path)

            except Exception as e:
                print(f"Ïò§Î•ò Î∞úÏÉù: {img_path} Ï≤òÎ¶¨ Ï§ë Î¨∏Ï†ú Î∞úÏÉù - {e}")

    print("\n‚úÖ Ïù¥ÎØ∏ÏßÄ Ï¶ùÍ∞ï Î∞è Ï†ÄÏû• ÏôÑÎ£å!")

# =====================================================================
# üîÅ Î™®Îì† FoldÏóê ÎåÄÌï¥ ÏûêÎèô Ï≤òÎ¶¨
# =====================================================================

if __name__ == '__main__':
    for fold_num in FOLD_RANGE:
        input_dir = os.path.join(BASE_INPUT_DIR, f"fold_{fold_num}", "train")
        output_dir = os.path.join(BASE_OUTPUT_DIR, f"fold_{fold_num}", "train")
        augment_and_save_images(input_dir, output_dir, NUM_AUGMENTATIONS_PER_IMAGE)